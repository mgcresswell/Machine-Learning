{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SVM.ipynb","provenance":[{"file_id":"1n_dz3FQSbeWEpqcEFhQOijU16GJ4YM5H","timestamp":1607892315975},{"file_id":"10SKngrrhWbm5GJg4kjTGy_Thx7wtjbt0","timestamp":1607400793965}],"collapsed_sections":[],"authorship_tag":"ABX9TyO/MtALdZjvMUzYu9NbjZ2O"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"sElgHsq8z-vk"},"source":["Mike Cresswell: Support Vector Machine Implementation"]},{"cell_type":"markdown","metadata":{"id":"Z87LAnjv0iQA"},"source":["SVM Classifying on TF-IDF Vectorized Text and Source"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jP6k18WljBa2","executionInfo":{"status":"ok","timestamp":1607892186306,"user_tz":360,"elapsed":2089,"user":{"displayName":"Mike Cresswell","photoUrl":"","userId":"05784128764127520699"}},"outputId":"6184e285-0e4c-4921-afc0-5092b73aa6d0"},"source":["#Code Classifies on Text and Source\n","#Using Linear SVM Kernel\n","import pandas as pd\n","import numpy as np\n","import time\n","import io\n","import requests\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn import svm\n","from sklearn.model_selection import KFold \n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from sklearn.model_selection import cross_val_score\n","\n","#Get Processed Data\n","url=\"https://raw.githubusercontent.com/mgcresswell/TCSS555-Project/main/deceptive-opinion_processed.csv\"\n","s=requests.get(url).content\n","Corpus = pd.read_csv(io.StringIO(s.decode('utf-8')))\n","\n","#Set Y\n","y = Corpus['deceptive']\n","#Drop unused X columns\n","X = Corpus.drop(['id','deceptive','hotel','polarity'], axis=1)\n","\n","#Encode Class Labels\n","label_encoder = LabelEncoder()\n","y = label_encoder.fit_transform(y)\n","sourceEncoded = label_encoder.fit_transform(X['source'])\n","\n","#One hot encode source label\n","onehot_encoder = OneHotEncoder(sparse=False)\n","sourceEncoded = sourceEncoded.reshape(len(sourceEncoded), 1)\n","X['source'] = onehot_encoder.fit_transform(sourceEncoded)\n","\n","#Vectorize text using tfidf vector\n","Tfidf_vect = TfidfVectorizer(max_features=1288)\n","Tfidf_vect.fit(Corpus['text'])\n","Text_Idf = Tfidf_vect.transform(X['text'])\n","X['text'] = Text_Idf.toarray()\n","\n","#Train/Test Split\n","split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n","for train_index, test_index in split.split(X, y):\n","   Train_X, Test_X = X.loc[train_index], X.loc[test_index]\n","   Train_Y, Test_Y = y[train_index], y[test_index]\n","\n","#Initialize model class\n","SVM = svm.SVC(kernel='linear')\n","start = time.perf_counter()\n","SVM.fit(Train_X, Train_Y)\n","stop = time.perf_counter()\n","\n","#Test Accuracy \n","y_pred = SVM.predict(Test_X)\n","test_Accuracy = accuracy_score(Test_Y, y_pred)*100\n","\n","#Test Accuracy \n","y_pred = SVM.predict(Train_X)\n","train_Accuracy = accuracy_score(Train_Y, y_pred)*100\n","\n","#measure cross validation\n","crossvalMean = cross_val_score(SVM, X, y, cv=10).mean()*100\n","\n","#get training time\n","curTime = stop - start;\n","print(f\"Training Time = {curTime:0.8f} Seconds\")\n","print(f\"Test Accuracy = {test_Accuracy}\")\n","print(f\"Train Accuracy = {train_Accuracy}\")\n","print(f\"Cross Validation Mean = {crossvalMean}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training Time = 0.00520728 Seconds\n","Test Accuracy = 100.0\n","Train Accuracy = 100.0\n","Cross Validation Mean = 100.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6JgdEtNXgPTV","executionInfo":{"status":"ok","timestamp":1607892242723,"user_tz":360,"elapsed":34250,"user":{"displayName":"Mike Cresswell","photoUrl":"","userId":"05784128764127520699"}},"outputId":"394213e9-42fb-4e96-e92c-9e653bcc2f40"},"source":["#Code Only Classifies on Text\n","#Using Linear SVM Kernel\n","import pandas as pd\n","import numpy as np\n","import time\n","import io\n","import requests\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn import svm\n","from sklearn.model_selection import KFold \n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from sklearn.model_selection import cross_val_score\n","\n","url=\"https://raw.githubusercontent.com/mgcresswell/TCSS555-Project/main/deceptive-opinion_processed.csv\"\n","s=requests.get(url).content\n","Corpus = pd.read_csv(io.StringIO(s.decode('utf-8')))\n","\n","y = Corpus['deceptive']\n","X =  np.array(Corpus['text'])\n","\n","label_encoder = LabelEncoder()\n","y = label_encoder.fit_transform(y)\n","\n","Tfidf_vect = TfidfVectorizer(max_features=1288)\n","Tfidf_vect.fit(X)\n","Text_Idf = Tfidf_vect.transform(X)\n","X = Text_Idf.toarray()\n","\n","split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n","for train_index, test_index in split.split(X, y):\n","   Train_X, Test_X = X[train_index], X[test_index]\n","   Train_Y, Test_Y = y[train_index], y[test_index]\n","\n","\n","SVM = svm.SVC(kernel='linear')\n","start = time.perf_counter()\n","SVM.fit(Train_X, Train_Y)\n","stop = time.perf_counter()\n","\n","#Test Accuracy \n","y_pred = SVM.predict(Test_X)\n","test_Accuracy = accuracy_score(Test_Y, y_pred)*100\n","\n","#Test Accuracy \n","y_pred = SVM.predict(Train_X)\n","train_Accuracy = accuracy_score(Train_Y, y_pred)*100\n","\n","crossvalMean = cross_val_score(SVM, X, y, cv=10).mean()\n","\n","curTime = stop - start;\n","print(f\"Training Time = {curTime:0.8f} Seconds\")\n","print(f\"Test Accuracy = {test_Accuracy}\")\n","print(f\"Train Accuracy = {train_Accuracy}\")\n","print(f\"Cross Validation Mean = {crossvalMean}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training Time = 1.71617123 Seconds\n","Test Accuracy = 87.91666666666667\n","Train Accuracy = 96.78571428571429\n","Cross Validation Mean = 0.8674999999999999\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HleasQrZP_fu","executionInfo":{"status":"ok","timestamp":1607892279148,"user_tz":360,"elapsed":2871,"user":{"displayName":"Mike Cresswell","photoUrl":"","userId":"05784128764127520699"}},"outputId":"aaf6538d-9a57-42c9-d9d6-6b37aefb2064"},"source":["#Uses RBF Kernel & Feature Engineering\r\n","#Features used for classification determined by results\r\n","#from SVM_RBF_Tuning functions\r\n","import pandas as pd\r\n","import numpy as np\r\n","import time\r\n","import io\r\n","import requests\r\n","from sklearn.preprocessing import LabelEncoder\r\n","from sklearn.preprocessing import OneHotEncoder\r\n","from sklearn.feature_extraction.text import TfidfVectorizer\r\n","from sklearn import svm\r\n","from sklearn.model_selection import KFold \r\n","from sklearn.metrics import classification_report\r\n","from sklearn.metrics import accuracy_score\r\n","from sklearn.model_selection import StratifiedShuffleSplit\r\n","from sklearn.model_selection import cross_val_score\r\n","\r\n","url=\"https://raw.githubusercontent.com/mgcresswell/TCSS555-Project/main/deceptive-opinion_processed.csv\"\r\n","s=requests.get(url).content\r\n","processed = pd.read_csv(io.StringIO(s.decode('utf-8'))) \r\n","\r\n","url=\"https://raw.githubusercontent.com/mgcresswell/TCSS555-Project/main/deceptive-opinion.csv\"\r\n","s=requests.get(url).content\r\n","raw = pd.read_csv(io.StringIO(s.decode('utf-8'))) \r\n","\r\n","y = processed['deceptive']\r\n","X = processed.drop(['id','deceptive','source','hotel','polarity'], axis=1)\r\n","\r\n","#Feature Engineering\r\n","punc = ['`','~','!','(',')','_','-','{','[','}','}',':',';','\"',',','.','?','/','\"\"']\r\n","X['word_count'] = raw[\"text\"].apply(lambda x: len(str(x).split(\" \")))\r\n","X['sentence_count'] = raw[\"text\"].apply(lambda x: len(str(x).split(\".\")))\r\n","X['num_unique_words'] = raw['text'].apply(lambda x: len(set(w for w in x.split())))\r\n","X['avg_sentence_length'] = X['word_count'] / X['sentence_count']\r\n","X['punc_count'] = raw['text'].apply(lambda x : len([a for a in x if a in punc]))\r\n","X['capitals'] = raw['text'].apply(lambda comment: sum(1 for c in comment if c.isupper()))\r\n","X['num_question_marks'] = raw['text'].apply(lambda x: x.count('?'))\r\n","X['num_symbols'] = raw['text'].apply(lambda x: sum(x.count(w) for w in '*&$%'))\r\n","X['words_vs_unique'] = X['num_unique_words'] / X['word_count']\r\n","\r\n","X = X.drop(['word_count','sentence_count','num_unique_words'], axis=1)\r\n","\r\n","label_encoder = LabelEncoder()\r\n","y = label_encoder.fit_transform(y)\r\n","\r\n","Tfidf_vect = TfidfVectorizer(max_features=3500)\r\n","Tfidf_vect.fit(X['text'])\r\n","Text_Idf = Tfidf_vect.transform(X['text'])\r\n","X['text'] = Text_Idf.toarray()\r\n","\r\n","split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\r\n","for train_index, test_index in split.split(X, y):\r\n","   Train_X, Test_X = X.loc[train_index], X.loc[test_index]\r\n","   Train_Y, Test_Y = y[train_index], y[test_index]\r\n","\r\n","\r\n","SVM = svm.SVC(kernel='rbf', gamma='scale')\r\n","start = time.perf_counter()\r\n","SVM.fit(Train_X, Train_Y)\r\n","stop = time.perf_counter()\r\n","\r\n","#Test Accuracy \r\n","y_pred = SVM.predict(Test_X)\r\n","test_Accuracy = accuracy_score(Test_Y, y_pred)*100\r\n","\r\n","#Test Accuracy \r\n","y_pred = SVM.predict(Train_X)\r\n","train_Accuracy = accuracy_score(Train_Y, y_pred)*100\r\n","\r\n","crossvalMean = cross_val_score(SVM, X, y, cv=10).mean()\r\n","\r\n","curTime = stop - start;\r\n","print(f\"Training Time = {curTime:0.8f} Seconds\")\r\n","print(f\"Test Accuracy = {test_Accuracy}\")\r\n","print(f\"Training Accuracy = {train_Accuracy}\")\r\n","print(f\"Cross Validation Mean = {crossvalMean}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training Time = 0.04814170 Seconds\n","Test Accuracy = 71.45833333333333\n","Training Accuracy = 67.05357142857142\n","Cross Validation Mean = 0.675\n"],"name":"stdout"}]}]}