{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cartpole_DeepQlearning+ER+TargetNetwork.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2nepvJHMNg6",
        "outputId": "de92a412-876b-4b76-f4cc-c367dc7454fc"
      },
      "source": [
        "!pip install numpy\r\n",
        "!pip install gym\r\n",
        "\r\n",
        "import numpy as np #for our Qtable\r\n",
        "import gym #for our cartpole Environment\r\n",
        "import random #to generate random numbers\r\n",
        "import pandas\r\n",
        "from collections import deque\r\n",
        "\r\n",
        "#neural network packages\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "from tensorflow.python.keras import utils\r\n",
        "\r\n",
        "#code for rendering gui\r\n",
        "!apt-get install python-opengl -y\r\n",
        "!apt install xvfb -y\r\n",
        "!pip install pyvirtualdisplay\r\n",
        "!pip install pyglet==1.4.0\r\n",
        "!apt-get install x11-utils\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from IPython import display as ipythondisplay\r\n",
        "from pyvirtualdisplay import Display\r\n",
        "display = Display(visible=0, size=(1400, 900))\r\n",
        "display.start()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.19.5)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (0.17.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.19.5)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python-opengl is already the newest version (3.1.0+dfsg-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 13 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.8).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 13 not upgraded.\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.6/dist-packages (2.0)\n",
            "Requirement already satisfied: EasyProcess in /usr/local/lib/python3.6/dist-packages (from pyvirtualdisplay) (0.3)\n",
            "Requirement already satisfied: pyglet==1.4.0 in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet==1.4.0) (0.16.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "x11-utils is already the newest version (7.7+3build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 13 not upgraded.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7f6d743e8eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsuMbjW8MUkG"
      },
      "source": [
        "#discreization parameters\r\n",
        "n_bins = 8\r\n",
        "n_bins_angle = 10\r\n",
        "# Number of states is huge so in order to simplify the situation\r\n",
        "# we discretize the space to: 10 ** number_of_features\r\n",
        "cart_position_bins = pandas.cut([-2.4, 2.4], bins=n_bins, retbins=True)[1][1:-1]\r\n",
        "pole_angle_bins = pandas.cut([-2, 2], bins=n_bins_angle, retbins=True)[1][1:-1]\r\n",
        "cart_velocity_bins = pandas.cut([-1, 1], bins=n_bins, retbins=True)[1][1:-1]\r\n",
        "angle_rate_bins = pandas.cut([-3.5, 3.5], bins=n_bins_angle, retbins=True)[1][1:-1]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfo3gY2YQ7LR"
      },
      "source": [
        "\r\n",
        "def to_bin(value, bins):\r\n",
        "    return np.digitize(x=[value], bins=bins)[0]\r\n",
        "\r\n",
        "def build_state(features):\r\n",
        "    return int(\"\".join(map(lambda feature: str(int(feature)), features)))\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "te_Y-2MOOdx8"
      },
      "source": [
        "class DQN():\r\n",
        "  def __init__(self,state_space,action_space,weights_file):\r\n",
        "    self.learning_rate = 0.2          # Learning rate\r\n",
        "    self.gamma = 0.95                 # Discounting rate\r\n",
        "\r\n",
        "    # Exploration parameters\r\n",
        "    self.epsilon = 0.99                 # Exploration rate\r\n",
        "    self.max_epsilon = 0.99             # Exploration probability at start\r\n",
        "    self.min_epsilon = 0.1            # Minimum exploration probability \r\n",
        "    self.decay_rate = 0.995            # Exponential decay rate for exploration prob\r\n",
        "\r\n",
        "    #neural network parameters\r\n",
        "    self.state_space = state_space\r\n",
        "    self.action_space=action_space\r\n",
        "    self.batch_size =16\r\n",
        "    self.input_size = 1\r\n",
        "    self.output_size = action_space.n\r\n",
        "    self.model = self.buildQNetwork()\r\n",
        "    self.target = self.buildQNetwork()\r\n",
        "    self.memory = deque(maxlen=2000)  #doubel ended queue for storing the transitions\r\n",
        "    self.target_update_interval = 4\r\n",
        "    self.weights_file = weights_file\r\n",
        "\r\n",
        "  def memorize(self, state, action, reward, next_state, done):\r\n",
        "        self.memory.append((state, action, reward, next_state, done))\r\n",
        "  \r\n",
        "  def updateTarget(self,steps):\r\n",
        "    if steps >= self.batch_size and steps % self.target_update_interval == 0:\r\n",
        "      self.target.set_weights(self.model.get_weights())\r\n",
        "      print(\"target updated\")\r\n",
        "\r\n",
        "  def load_weights(self):\r\n",
        "    self.model.load_weights(self.weights_file)\r\n",
        "\r\n",
        "  def save_weights(self):\r\n",
        "    print(\"Saving wights to file\")\r\n",
        "    self.model.save_weights(self.weights_file)\r\n",
        "\r\n",
        "  \r\n",
        "  def buildQNetwork(self):\r\n",
        "    model = Sequential()\r\n",
        "    model.add(Dense(10, input_dim=self.input_size, activation='relu'))#fully connected\r\n",
        "    model.add(Dense(10, activation='relu'))\r\n",
        "    model.add(Dense(self.output_size))\r\n",
        "    model.compile(loss='mse', optimizer='adam')\r\n",
        "    return model\r\n",
        "    \r\n",
        "  def chooseAction(self,state,isEpsilonGreedy):\r\n",
        "    exp_exp_tradeoff = random.uniform(0, 1)\r\n",
        "    \r\n",
        "    if exp_exp_tradeoff > self.epsilon or not isEpsilonGreedy:\r\n",
        "        qval = self.model.predict(np.reshape(state,(1, self.input_size)))[0]\r\n",
        "        maxqval = max(qval)\r\n",
        "        action= np.where(qval == maxqval)[0][0]\r\n",
        "        print(\"Qaction\",action)\r\n",
        "       \r\n",
        "    else:\r\n",
        "        action = self.action_space.sample()\r\n",
        "        print(\"random action\",action)\r\n",
        "    return action\r\n",
        "\r\n",
        "  def updateEpsilon(self,steps):\r\n",
        "    self.epsilon *= self.decay_rate\r\n",
        "    if(self.epsilon < self.min_epsilon):\r\n",
        "      self.epsilon = self.min_epsilon\r\n",
        "    #print(self.epsilon)\r\n",
        "    #self.epsilon = self.min_epsilon + (self.max_epsilon - self.min_epsilon)*np.exp(-self.decay_rate*steps) \r\n",
        "\r\n",
        "  def calcualteTargetValue(self,state, action, reward, next_state, isDone):\r\n",
        "    qnext = self.target.predict(np.reshape(next_state,(1, self.input_size)))\r\n",
        "    maxqval = max(qnext[0])\r\n",
        "   \r\n",
        "    if done:\r\n",
        "      target_value = reward\r\n",
        "    else:\r\n",
        "      target_value = reward + self.gamma *maxqval \r\n",
        "\r\n",
        "    return target_value\r\n",
        "\r\n",
        "  def train(self):\r\n",
        "    X_train = np.zeros((self.batch_size, self.input_size))\r\n",
        "    Y_train = np.zeros((self.batch_size, self.output_size))\r\n",
        "    loss =0\r\n",
        "    if len(self.memory)<self.batch_size:\r\n",
        "      print(\"memory insufficient for training\")\r\n",
        "      return loss\r\n",
        "    mini_batch = random.sample(self.memory, self.batch_size)\r\n",
        "    for index_rep in range(self.batch_size):\r\n",
        "      state,action,reward,next_state,isDone = mini_batch[index_rep]\r\n",
        "      X_train[index_rep] = state\r\n",
        "      Y_train[index_rep][action] = self.calcualteTargetValue(state,action,reward,next_state,isDone)\r\n",
        "    loss = self.model.train_on_batch(X_train, Y_train)\r\n",
        "    return loss\r\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "kmB6UXlmL58S",
        "outputId": "60022d51-8d04-458f-9b2f-78255c58bca5"
      },
      "source": [
        "env = gym.make(\"CartPole-v1\")\r\n",
        "\r\n",
        "rewards = []\r\n",
        "weights_file = 'dqn.h5'\r\n",
        "learner = DQN(env.observation_space,env.action_space,weights_file)\r\n",
        "total_episodes = 2     # Total episodes\r\n",
        "max_steps = 10               # Max steps per episode\r\n",
        "total_steps=0 \r\n",
        "for episode in range(total_episodes): \r\n",
        "    # Reset the environment\r\n",
        "    cart_position, pole_angle, cart_velocity, angle_rate_of_change = env.reset()\r\n",
        "  \r\n",
        "    state = build_state([to_bin(cart_position, cart_position_bins),\r\n",
        "                        to_bin(pole_angle, pole_angle_bins),\r\n",
        "                        to_bin(cart_velocity, cart_velocity_bins),\r\n",
        "                        to_bin(angle_rate_of_change, angle_rate_bins)])\r\n",
        "    step = 0\r\n",
        "    done = False\r\n",
        "    total_rewards = 0\r\n",
        "    loss =0\r\n",
        "    prev_screen = env.render(mode='rgb_array')\r\n",
        "    plt.imshow(prev_screen)\r\n",
        "    for step in range(max_steps): \r\n",
        "      screen = env.render(mode='rgb_array')\r\n",
        "      plt.imshow(screen)\r\n",
        "      ipythondisplay.clear_output(wait=True)\r\n",
        "      ipythondisplay.display(plt.gcf())\r\n",
        "    \r\n",
        "      \r\n",
        "      action = learner.chooseAction(state,True)\r\n",
        "      # Take the action (a) and observe the outcome state(s') and reward (r)\r\n",
        "      observation, reward, done, info = env.step(action)\r\n",
        "\r\n",
        "      cart_position, pole_angle, cart_velocity, angle_rate_of_change = observation\r\n",
        "      new_state = build_state([to_bin(cart_position, cart_position_bins),\r\n",
        "                        to_bin(pole_angle, pole_angle_bins),\r\n",
        "                        to_bin(cart_velocity, cart_velocity_bins),\r\n",
        "                        to_bin(angle_rate_of_change, angle_rate_bins)])\r\n",
        "\r\n",
        "      learner.memorize(state,action,reward, new_state,done)\r\n",
        "      #Calcualte the loss and train (optimize) the Q-network\r\n",
        "      \r\n",
        "      loss +=learner.train()\r\n",
        "      learner.updateTarget(total_steps)\r\n",
        "\r\n",
        "      total_rewards += reward\r\n",
        "      total_steps += 1\r\n",
        "      # Our new state is state\r\n",
        "      state = new_state\r\n",
        "      \r\n",
        "      # If done (if we're dead) : finish episode\r\n",
        "      if done == True: \r\n",
        "          break\r\n",
        "  # Reduce epsilon (because we need less and less exploration)\r\n",
        "      learner.updateEpsilon(total_steps)\r\n",
        "    print(\"loss=\",loss)\r\n",
        "    rewards.append(total_rewards)\r\n",
        "    ipythondisplay.clear_output(wait=True)\r\n",
        "print(rewards, max(rewards))\r\n",
        "print (\"Score over time: \" +  str(sum(rewards)/total_episodes))\r\n",
        "learner.save_weights()\r\n",
        "\r\n",
        "env.reset()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[10.0, 10.0] 10.0\n",
            "Score over time: 10.0\n",
            "Saving wights to file\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.04377696,  0.03999031,  0.03159624,  0.01659884])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "4phJ2Ad9N0_q",
        "outputId": "73d79a3e-2130-4d19-ff1c-646db22611a0"
      },
      "source": [
        "for episode in range(5):\r\n",
        "    cart_position, pole_angle, cart_velocity, angle_rate_of_change = env.reset()\r\n",
        "   \r\n",
        "    state = build_state([to_bin(cart_position, cart_position_bins),\r\n",
        "                         to_bin(pole_angle, pole_angle_bins),\r\n",
        "                         to_bin(cart_velocity, cart_velocity_bins),\r\n",
        "                         to_bin(angle_rate_of_change, angle_rate_bins)])\r\n",
        "    step = 0\r\n",
        "    done = False\r\n",
        "    print(\"****************************************************\")\r\n",
        "    print(\"EPISODE \", episode)\r\n",
        "    prev_screen = env.render(mode='rgb_array')\r\n",
        "    plt.imshow(prev_screen)\r\n",
        "    for step in range(max_steps):\r\n",
        "        \r\n",
        "        # Take the action (index) that have the maximum expected future reward given that state\r\n",
        "        action = learner.chooseAction(state,False)\r\n",
        "        \r\n",
        "        observation, reward, done, info = env.step(action)\r\n",
        "        cart_position, pole_angle, cart_velocity, angle_rate_of_change = observation\r\n",
        "        new_state = build_state([to_bin(cart_position, cart_position_bins),\r\n",
        "                          to_bin(pole_angle, pole_angle_bins),\r\n",
        "                          to_bin(cart_velocity, cart_velocity_bins),\r\n",
        "                          to_bin(angle_rate_of_change, angle_rate_bins)])\r\n",
        "        screen = env.render(mode='rgb_array')\r\n",
        "        plt.imshow(screen)\r\n",
        "        ipythondisplay.clear_output(wait=True)\r\n",
        "        ipythondisplay.display(plt.gcf())\r\n",
        "        if done:\r\n",
        "          break\r\n",
        "        state = new_state\r\n",
        "    ipythondisplay.clear_output(wait=True)\r\n",
        "env.close()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}